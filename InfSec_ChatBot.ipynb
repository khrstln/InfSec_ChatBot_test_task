{"cells":[{"cell_type":"markdown","metadata":{"id":"UVL3Zh1bYd2R"},"source":["## Цель задания\n","\n","Необходимо разработать систему, использующую метод RAG для предоставления ответов на вопросы, связанные с информационной безопасностью. Система должна сочетать генерацию текста при помощи языковой модели с извлечением релевантной информации из локальной базы знаний\n","\n","## Задачи\n","\n","1. Создание базы знаний на основании информации из открытых источников\n","2. Разработка системы, использующей метод RAG, на основании открытой LLM для ответов на вопросы пользователей по теме информационной безопасности\n","3. Разработка промтов для взаимодействия пользователя с системой\n","\n","## План выполнения задач\n","\n","1. В качестве базы данных использовать русскоязычные научные статьи на тему информационной безопасности. Поиск релевантных статей осуществляется с помощью Google Scholar\n","2. В соответствии с требованиями использовать библиотеку langchain и открытые LLM из HuggingFaceHub\n","3. Настройка промтов с помощью шаблонов из библиотеку langchain\n","\n","\n","\n","Полное описание тестового задания можно найти [здесь](https://docs.google.com/document/d/1n-vVyTAjSv-lCl5Iiw6R9sopPfz9ta5vIeRsK3RGEF0/edit?usp=sharing)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3680,"status":"ok","timestamp":1726836767287,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"SUwHCpmyQet3","outputId":"2419bf34-4146-47df-ef22-50a2bd0ead00"},"outputs":[],"source":["# !pip install langchain langchain-community transformers sentence-transformers faiss-cpu faiss-gpu huggingface-hub bert_score"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"rV0swqJZQNaP"},"outputs":[],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.llms import HuggingFaceHub\n","from langchain.chains import RetrievalQA\n","from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n","from langchain.schema import HumanMessage, SystemMessage\n","from langchain.schema.runnable import RunnablePassthrough\n","from langchain.schema.output_parser import StrOutputParser\n","from langchain_community.document_loaders import WebBaseLoader, TextLoader\n","from langchain.chains import create_retrieval_chain\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","import os\n","import warnings\n","from dotenv import load_dotenv\n","\n","\n","from bert_score import score\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"2JPy-AeABru8"},"outputs":[],"source":["data_filename = \"data/data.txt\""]},{"cell_type":"markdown","metadata":{"id":"Z_6EEP8MQNaT"},"source":["### Выбор модели\n","\n","В качестве моделей рассматривались gpt-2, Llama-3.1-8B и Mixtral-8x7B-Instruct-v0.1.\n","\n","Модель gpt-2 имеет недостаточный размер контекста для текущей задачи, а также хуже справляется с задачами генерации текста на основе базы знаний, чем более большие модели.\n","\n","Модель Llama-3.1-8B имеет больший размер контекста, чем gpt-2, и заметно лучше справляется с задачами генерации текста на основании предложенной базы знаний. Однако с развертыванием данной модели в Google Colab возникают трудности.\n","\n","Наиболее удачно с задачами генерации текста справляется mistralai/Mixtral-8x7B-Instruct-v0.1, поэтому для текущей задачи был сделан выбор в пользу этой модели."]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["load_dotenv()"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"shPKabz-QNaU"},"outputs":[],"source":["repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n","llm = HuggingFaceHub(repo_id=repo_id,\n","                     model_kwargs={\"temperature\": 0.01, \"top-k\": 20, \"top-p\": 0.5,\n","                                   \"random_seed\": 42, \"max_length\": 4096},\n","                     huggingfacehub_api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN'))"]},{"cell_type":"markdown","metadata":{"id":"WCtivP_cQNaY"},"source":["### Создание базы знаний\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8_3amx2eY-hP"},"source":["В качестве базы знаний были взяты 5 статей по тематике информационной безопасности, найденные с помощью Google Scholar. Содержимое статей было конвертировано в текст с помощью библиотеки pdfminer и сохранено в файл data.txt для дальнейшего использования для поиска релевантной информации."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"Ey-h6-YeQNaZ"},"outputs":[],"source":["loader = TextLoader(data_filename, encoding='utf-8')\n","docs = loader.load()\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n","\n","documents = text_splitter.split_documents(docs)"]},{"cell_type":"markdown","metadata":{"id":"EHeQFxw7vSbP"},"source":["### Выбор модели для эмбеддинга\n","\n","Изначально для построения эмбеддингов использовалась модель sentence-transformers/all-MiniLM-L6-v2. Преимуществом модели была высокая скорость работы, однако модель предназначена для работы с английским языком. Поэтому была выбрана модель intfloat/multilingual-e5-large, которая показывает результаты лучше при использовании русского языка. Однако использование этой модели приводит к тому, что это занимает значительно больше времени."]},{"cell_type":"code","execution_count":63,"metadata":{"id":"bAqlXvP3vFLn"},"outputs":[],"source":["embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n","\n","vector = FAISS.from_documents(documents, embeddings)"]},{"cell_type":"markdown","metadata":{"id":"53YshdfjaHvx"},"source":["### Настройка промта"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"1kAgC98yQNaZ"},"outputs":[],"source":["RAG_TEMPLATE = \"\"\"Вы являетесь экспертом в области кибербезопасности.\n","    Ответьте на вопросы пользователя на русском языке, используя информацию из текста, находящегося внутри тегов context.\n","    Если вы не знаете ответ, просто сообщите, что не знаете. Используйте максимум 3 предложения\n","\n","    <context>\n","    {context}\n","    </context>\n","\n","    Ответьте на следующий вопрос:\n","\n","    {input}\"\"\"\n","\n","rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"Ue13fZ_10OeC"},"outputs":[],"source":["def format_docs(docs):\n","    '''Convert loaded documents into strings by concatenating their content and ignoring metadata'''\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"2gp-lEGhQNaa"},"outputs":[],"source":["retriever = vector.as_retriever(search_kwargs={\"k\": 5})\n","retrieval_chain = ({\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n","    | rag_prompt\n","    | llm\n","    | StrOutputParser()\n",")"]},{"cell_type":"markdown","metadata":{"id":"FwM94HspafZo"},"source":["### Получение ответов на основании базы знаний"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3211,"status":"ok","timestamp":1726837051089,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"WSaNV9aXQNaa","outputId":"a77a442c-210c-413f-957a-5d772874c2bb"},"outputs":[{"ename":"BadRequestError","evalue":" (Request ID: 3wVyACe-bngSHnyIU0CIa)\n\nBad request:\nAuthorization header is correct, but the token seems invalid","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mЧто такое информационная безопасность?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3013\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3011\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3012\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3013\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3014\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:391\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    389\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    403\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:756\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    750\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    754\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    755\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         )\n\u001b[0;32m    949\u001b[0m     ]\n\u001b[1;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:793\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    792\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    794\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:780\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    772\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 780\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    788\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1514\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1511\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m   1513\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1514\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1516\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1517\u001b[0m     )\n\u001b[0;32m   1518\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\llms\\huggingface_hub.py:138\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    136\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 138\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:273\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m     )\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n","\u001b[1;31mBadRequestError\u001b[0m:  (Request ID: 3wVyACe-bngSHnyIU0CIa)\n\nBad request:\nAuthorization header is correct, but the token seems invalid"]}],"source":["response = retrieval_chain.invoke(\"Что такое информационная безопасность?\")\n","print(response)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2655,"status":"ok","timestamp":1726837053740,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"yGMArPuj13wG","outputId":"c33ebd32-c499-4b08-c0f9-35f0d0624274"},"outputs":[{"ename":"BadRequestError","evalue":" (Request ID: fgZiM5Yomnjf48P88DWZK)\n\nBad request:\nAuthorization header is correct, but the token seems invalid","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mЧто такое троянский конь?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3013\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3011\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3012\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3013\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3014\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:391\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    389\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    403\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:756\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    750\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    754\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    755\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         )\n\u001b[0;32m    949\u001b[0m     ]\n\u001b[1;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:793\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    792\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    794\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:780\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    772\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 780\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    788\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    791\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1514\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1511\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m   1513\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1514\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1516\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1517\u001b[0m     )\n\u001b[0;32m   1518\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\llms\\huggingface_hub.py:138\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    136\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 138\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:273\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n","File \u001b[1;32mc:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m     )\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n","\u001b[1;31mBadRequestError\u001b[0m:  (Request ID: fgZiM5Yomnjf48P88DWZK)\n\nBad request:\nAuthorization header is correct, but the token seems invalid"]}],"source":["response = retrieval_chain.invoke(\"Что такое троянский конь?\")\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2070,"status":"ok","timestamp":1726837055807,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"ALBuHnLcQNaa","outputId":"7f18be0a-c122-43e7-ceb3-a35cc40f03a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Вы являетесь экспертом в области кибербезопасности.\n","    Ответьте на вопросы пользователя на русском языке, используя информацию из текста, находящегося внутри тегов context. \n","    Если вы не знаете ответ, просто сообщите, что не знаете. Используйте максимум 3 предложения\n","\n","    <context>\n","    гии в установленном формате электронных \n","сообщений. \n","\n","По заключению аналитиков, почти 99 % \n","всех  киберпреступлений  в  мире  связаны \n","с воровством денег. Наибольшую опасность \n","для  банков  сейчас  представляют  целевые \n","атаки,  ущерб  от  которых  в  прошлом  году \n","вырос почти на 300 %. Одна из атак стоила \n","российскому  банку  140  млн  руб.,  а  общая \n","сумма  хищений  выросла,  по  оценкам  экс-\n","пертов, до 2,5 млрд руб. [8].\n","\n","Всего за 2017 г. было зарегистрировано \n","не менее 21 атак «Кобальт Страйк». Атакам \n","подверглись более 240 кредитных организа-\n","ций, из них успешных атак было 11, сумма \n","ущерба превысила 1 млрд. руб. При этом 8 \n","из  11  пострадавших  организаций  не  явля-\n","лись  участниками  информационного  обме-\n","на с ФинЦЕРТом, на базе которого и обра-\n","зуют новый департамент [9].\n","\n","Проблемы  безопасности  и  цифровиза-\n","ции  тесно  взаимосвязаны,  на  это  следует \n","обращать внимание.\n","\n","Исследование, проведенное в Великобритании [5], выявило, что чем крупнее организация, тем \n","чаще она сталкивается с нарушениями информационной безопасности: 84% информационных атак \n","приходится на средние и крупные предприятия. Более того, интересен тот факт, что 16% организа-\n","ций не уверены в том, имели ли место случаи утечки информации, то есть существует доля неоп-\n","ределенности, на которую следует обратить пристальное внимание [там же].\n","\n","В статье рассмотрены проблемы обеспечения защиты информации в условиях цифровой экономики. \n","Цифровая экономика оказывает положительное влияние на все сферы жизни общества, но данные процес-\n","сы сопровождаются и негативными последствиями, которые связаны с угрозами потери конфиденциаль-\n","ной информации. Потеря экономической информации в условиях функционирования цифровой экономи-\n","ки становится все более реальной ситуацией. Особенно в условиях активной информатизации экономики \n","наибольшие потери наблюдаются в банковском секторе, за последние три года количество экономических \n","преступлений именно в банковском секторе возросло. В статье представлен анализ современного состоя-\n","ния цифровой экономики и выявлены проблемы с обеспечением информационной безопасности в данной \n","сфере. Так же проведен анализ количества утечек информации за 10 лет и сравнительный анализ причин \n","нарушения  информационной  безопасности  по  итогам  2016–2017  гг.  Необходимо  создание  эффективной\n","\n","Потеря  доверия  со  стороны  контрагентов  является  крайне  нежелательным  результатом  дея-\n","тельности, поэтому вопросы обеспечения информационной безопасности требуют решения, как на \n","государственном  уровне,  так  и  на  уровне  отдельных  организаций.  Информационные  атаки  могут \n","иметь мировой масштаб: в мае 2017 г. компьютеры в более чем 150 странах были заражены вирус-\n","ной  программой  WannaCry,  что  нарушило  деятельность  Национальной  службы  здравоохранения \n","Великобритании (NHS), испанской телекоммуникационной компании Telefónica, американской ло-\n","гистической компании FedEx, крупнейшего железнодорожного оператора Германии Deutsche Bahn \n","и многих других организаций по всему миру [8]; автомобильные концерны Nissan Motor и Renault \n","временно приостановили производство на нескольких производственных площадках [9].\n","\n","В данных условиях глобальные масшта-\n","бы  обретает  вопрос  защиты  персональных \n","данных.  Личная  информация  становится \n","одним из ценнейших активов. Наблюдается \n","рост случаев утечки информации. В первом \n","полугодии  2017  г.  аналитический  центр \n","InfoWatch зарегистрировал 925 случаев уте-\n","чек  конфиденциальной  информации  –  на \n","10 %  больше,  чем  за  аналогичный  период \n","2016 г. (рис. 1).\n","\n","В  целях  решения  проблемы  утечки  ин-\n","формации  необходимо  выявить  факторы, \n","которые способствуют потере информации. \n","Внешние атаки обусловили 10 из 20 зафик-\n","сированных  «мегаутечек»  (свыше  10  млн \n","ПДн на каждую), на которые пришлись 7,68 \n","млрд  скомпрометированных  записей  (98 % \n","общего  числа).  В 43  случаях  объем  ском-\n","прометированных  данных  превысил  1  млн \n","записей. В 53 % случаев виновными в утеч-\n","ках  оказались  сотрудники  компаний,  в  2 % \n","случаев высшие руководители и иные при-\n","вилегированные пользователи (рис. 2, 3).\n","    </context>\n","\n","    Ответьте на следующий вопрос:\n","\n","    Какая доля киберпреступлений в мире связана с воровством денег?\n","\n","    Ответ:\n","    Почти 99 % всех киберпреступлений в мире связаны с воровством денег.\n"]}],"source":["response = retrieval_chain.invoke(\"Какая доля киберпреступлений в мире связана с воровством денег?\")\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3340,"status":"ok","timestamp":1726837059143,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"wixTtArL4fzJ","outputId":"a8f6fcc9-556e-4f37-960c-5fa5868bef34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Human: Вы являетесь экспертом в области кибербезопасности.\n","    Ответьте на вопросы пользователя на русском языке, используя информацию из текста, находящегося внутри тегов context. \n","    Если вы не знаете ответ, просто сообщите, что не знаете. Используйте максимум 3 предложения\n","\n","    <context>\n","    18  декабря  2017 г.  Правительственная \n","комиссия  по  использованию  информаци-\n","онных технологий для улучшения качества \n","жизни  и  условий  ведения  предпринима-\n","тельской  деятельности  утвердила  две  про-\n","граммы  «Цифровая  экономика  Российской \n","Федерации» на 2018–2024 гг.\n","\n","План  предусматривает  финансирова-\n","ние  из  федерального  бюджета  в  размере \n","22 333 млн руб. и внебюджетное финанси-\n","рование – 11 710 млн руб.\n","\n","Результаты исследования  \n","и их обсуждение\n","\n","Количество утечек информации возрас-\n","тает с каждым годом, особенно в условиях \n","\n","формирования  цифровой  экономики,  так \n","с 2006 по 2017 г. количество утечек конфи-\n","денциальной информации возросло в 8 раз. \n","Основной  причиной  потери  конфиденци-\n","альной информации по-прежнему остаются \n","внутренние факторы, так основной процент \n","приходится  на  сотрудников,  более  полови-\n","ны  утечек  происходит  именно  по  вине  со-\n","трудников,  но  следует  отметить  снижение \n","данного показателя в 2017 г. по сравнению \n","с 2016 г.\n","\n","Также  ожидается,  что  по  итогам  вы-\n","полнения  программы  будет  разработана \n","система мер поддержки российских произ-\n","водителей продуктов и услуг информацион-\n","но-компьютерных технологий, осуществля-\n","ющих патентование продуктов за рубежом.\n","\n","Утвержденный план содержит перечень \n","\n","целевых показателей и индикаторов.\n","\n","С 10 % в 2018 до 90 % в 2024 г. должна \n","увеличиться доля субъектов информацион-\n","ного  взаимодействия,  использующих  стан-\n","дарты безопасности в киберфизических си-\n","стемах и в части интернета вещей.\n","\n","Доля  граждан,  повысивших  грамот-\n","ность  в  сфере  информационной  безопас-\n","ности, медиапотребления и использования \n","интернет-сервисов, к 2024 г. должна соста-\n","вить 50 %.\n","\n","Выводы\n","\n","Резюмируя,  отметим,  что  «картина \n","получается  в  результате  довольно  безра-\n","достная»,  имея  в  виду  ситуацию  в  банков-\n","ском секторе, который сталкивается сейчас \n","с  давлением  со  стороны  финансовых  тех-\n","нологий,  вынуждающих  к  новым  инстру-\n","ментам, с другой стороны, операторы связи\n","\n","Межведомственная  комиссия  Мини-\n","стерства  цифрового  развития,  связи  и  мас-\n","совых  коммуникаций  Российской  Федера-\n","ции  разработала  проект  государственной \n","программы  «Цифровая  экономика»,  в  рам-\n","ках  которой  предусмотрен  переход  на  оте- \n","чественное  шифровальное  программное \n","обеспечение.\n","\n","Осуществить  полный  переход  участни-\n","ков  процесса  обмена  цифровой  информа-\n","цией  в  рамках  системы  «Цифровая  эконо-\n","мика» на российские системы шифрования \n","данных  разработчики  планируют  к  2021 г. \n","В рамках  данного  проекта  необходимо \n","встроить российские программы шифрова-\n","ния в программное обеспечение.\n","\n","В  мире  на  данный  момент  функцио-\n","нируют  две  школы  шифрования:  Россия \n","и  США.  Китай  также  начал  активно  зани-\n","маться данным вопросом.\n","\n","Необходимо  формирование  правового \n","фундамента для обеспечения информацион-\n","ной  безопасности  в  кредитно-финансовой \n","сфере», первым делом сославшись на про-\n","грамму  «Цифровая  экономика  Российской \n","Федерации»,  утвержденную  распоряжени-\n","ем  правительства  России  28  июля  2017 г., \n","одним из направлений которой определена \n","необходимость  нейтрализация  рисков,  свя-\n","занных с киберустойчивостью финансовых \n","организаций.  Важным  документом  являет-\n","ся  положение  Доктрины  информационной \n","безопасности России, принятой указом пре-\n","зидента в декабре 2016 г. \n","\n","Значимым \n","\n","событием  для  отрасли \n","в  2017 г.  стало  вступление  в  силу  закона \n","«О  безопасности  критической  информаци-\n","онной инфраструктуры РФ».\n","\n","Ключевые слова: информационная безопасность, цифровая экономика, конфиденциальная информация, \n","\n","блокчейн, информационные системы, киберустойчивость\n","\n","Старый  уклад  экономической  сферы  об-\n","щества на данном этапе активно вытесняется \n","таким  новым  направлением,  как  цифровая \n","экономика.  Цифровая  экономика  охватывает \n","все сферы общества и активно вовлекает как \n","физических, так и юридических лиц. Проис-\n","ходящие  изменения  в  сфере  экономики  спо-\n","собствуют  трансформации  и  других  сфер \n","жизни общества. Появляются новые профес-\n","\n","сии и рабочие места, которые требуют приоб-\n","ретения соответствующих знаний и навыков.\n","Построение модели цифровой экономи-\n","ки в Российской Федерации имеет ряд труд-\n","ностей,  которые  связаны  с  тем,  что  сама \n","экономическая система не является рыноч-\n","ной,  а  переход  к  цифровой  экономике  реа-\n","лизовали в основном в странах с рыночным \n","типом экономики.\n","    </context>\n","\n","    Ответьте на следующий вопрос:\n","\n","    Когда были утверждены программы «Цифровая  экономика  Российской Федерации» на 2018-2024 гг.?\n","\n","    Ответ: Правительственная комиссия по использованию информационных технологий для улучшения качества жизни и условий ведения предпринимательской деятельности утвердила две программы «Цифровая экономика Российской Федерации» на 2018–2024 гг. 18 декабря 2017 г.\n"]}],"source":["response = retrieval_chain.invoke(\"Когда были утверждены программы «Цифровая  экономика  Российской Федерации» на 2018-2024 гг.?\")\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"_rXFJcGpatm7"},"source":["### Получение ответов на вопросы без использования базы знаний"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2937,"status":"ok","timestamp":1726837062063,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"y1UVBZ2WLnEn","outputId":"c9c1a4ac-c3e1-46ee-f352-6c605440921a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Что такое информационная безопасность?\n","\n","Информационная безопасность - это совокупность мер, направленных на защиту информации от несанкционированного доступа, изменения, уничтожения, а также от потери конфиденциальности, целостности и доступности.\n","\n","Какие меры можно принять для обеспечения информационной безопасности?\n"]}],"source":["response = llm.invoke(\"Что такое информационная безопасность?\")\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2594,"status":"ok","timestamp":1726837064637,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"D8hAX7T-5Nzd","outputId":"b58e54cb-6a60-4db5-af62-36b8d847090b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Что такое троянский конь?\n","========================\n","\n","Троянский конь - это программа, которая выглядит как обычная, но на самом деле содержит вредоносный код.\n","\n","Троянские программы могут выполнять различные действия, например:\n","\n","- Скрытно устанавливать другие программы на компьютер\n","- Скрытно\n"]}],"source":["response = llm.invoke(\"Что такое троянский конь?\")\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2436,"status":"ok","timestamp":1726837067069,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"6mjyEYDXa7lh","outputId":"5223be29-79ef-495c-976f-e4e36c706fcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Какая доля киберпреступлений в мире связана с воровством денег?\n","\n","The majority of cybercrimes are financially motivated, with the most common types being identity theft, credit card fraud, and bank fraud. According to the FBI's Internet Crime Complaint Center, in 2020, the total losses from cybercrimes in the United States alone were over $4.2 billion, with the majority of those losses resulting from financial fraud. Globally, the cost of cybercrime is estimated to be in the trillions\n"]}],"source":["response = llm.invoke(\"Какая доля киберпреступлений в мире связана с воровством денег?\")\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2646,"status":"ok","timestamp":1726837069713,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"YF-MI6gtbAI0","outputId":"18657d9d-27cf-4742-cde0-485f733b7ef9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Когда были утверждены программы «Цифровая  экономика  Российской Федерации» на 2018-2024 гг.?\n","\n","Программы «Цифровая  экономика  Российской Федерации» на 2018-2024 гг. были утверждены постановлением Правительства РФ от 28.12.2017 № 1632.\n","\n","# Digital economy of the Russian Federation\n","\n","The digital economy of the Russian Federation is a set of economic relations associated with\n"]}],"source":["response = llm.invoke(\"Когда были утверждены программы «Цифровая  экономика  Российской Федерации» на 2018-2024 гг.?\")\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"9463PU4e5jEM"},"source":["### Сравнение ответов модели с использованием и без использования RAG\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336,"referenced_widgets":["f2511916b44b4c5a8d98985a138d14a1","cabed5f1ebe546a98977a9124d4188f5","9dfb9e0c35a14540adb9b156435a3559","96e0b2e1c9354424a61d20c2f84bc8ec","a4a2a63556f743fa8db0b93af8b9876e","cddb4e91388a4495928fb9b4dff517e1","7125359331174d94b3e0bca370c0ab3f","851d7da245b14adab7678bf32e2a8ddb","5084224c8be444e1a5360d26d1f60d95","577dfcf8e3584c48ab47e5cee8c364f2","3a2a1d855dad4038bddf32403bca197d","70836bb1f6b8424582b2410cb4a9f63f","7b3373417ef8465e8c892d8cfc979c86","d0a25884bd7e422881db7ce39d24e03a","895d1c76affd4253b1c821daa1835343","f99a79a2033941059af34dff55ed47ad","6caae4af9b964b73b6145eb7568f5237","899ab532917c465faee0d6d5e0d41b69","8fc08880b8ad4ad9955a0d40033f8df5","f9f2b750cb7f4412b6880c2bd6c141ae","f62e48f8ce494b79860da7938f452c0c","533f2c1749f94226bf0e787948963876","d5fd5899f0f2492c8181deaa5d2359d2","029f9bb071764be398ad2f464e4ee525","635e1a64653c43f7befed1bbccaaff67","083c422dc2e24daa90b9e95d039b45b9","6cb6d9352ab643bebced37bbc7755a3c","875b7782eeff43f0bed2d207500d7b06","57fd74bbca874284a0b76aa48cbf260e","fc7e00849c8748f1b957d11c758c669d","e9b4876fba9743f09c65ddd1c6eb0bb8","7dd1172318dc4f1a98f073d8904fb58a","c6b6fa53fe9c4c0e929377f22255a8a0","5df40df04aa54075b70c84a8f2e77aa5","af673a51922144b0b6b4757debb71554","60deac8cba034cae89f72a82b5ea53cd","55af2aa171f54f428e358497dc498b90","c290825bada64723977397109db2bd0e","fb8da34da8f04bcc96bde60a795e27fe","a1ba567c1994448d810b6d2da6958099","e208f899180b4d1199db791c6e8b1f47","bf92911e49544c8580f9eb5b6c7322dd","320872f5753f4c20b9f2f33fb0c88174","9f1f637ba8de406a8a1eb033a4dabe01"]},"executionInfo":{"elapsed":3880,"status":"ok","timestamp":1726837073590,"user":{"displayName":"Илия Хрусталев","userId":"09808473091939074965"},"user_tz":-180},"id":"1PPlpkvo5Wb2","outputId":"7c7aa65c-ec49-4e1f-f700-c904d3f1718a"},"outputs":[{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2511916b44b4c5a8d98985a138d14a1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70836bb1f6b8424582b2410cb4a9f63f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 1.15 seconds, 0.87 sentences/sec\n","calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5fd5899f0f2492c8181deaa5d2359d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5df40df04aa54075b70c84a8f2e77aa5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 1.52 seconds, 0.66 sentences/sec\n","F1 Score with RAG: 0.7767\n","\n","F1 Score without RAG: 0.7124\n"]}],"source":["with open('/content/drive/MyDrive/ChatBot тестовое/Answers_rag.txt', 'r', encoding='utf-8') as file:\n","    candidates_rag = [file.read()]\n","\n","with open('/content/drive/MyDrive/ChatBot тестовое/Answers_not_rag.txt', 'r', encoding='utf-8') as file:\n","    candidates_not_rag = [file.read()]\n","\n","with open('/content/drive/MyDrive/ChatBot тестовое/Answers_true.txt', 'r', encoding='utf-8') as file:\n","    references = [file.read()]\n","\n","P_rag, R_rag, F1_rag = score(candidates_rag, references, lang=\"ru\", verbose=True)\n","P_not_rag, R_not_rag, F1_not_rag = score(candidates_not_rag, references, lang=\"ru\", verbose=True)\n","\n","print(f\"F1 Score with RAG: {F1_rag.mean():.4f}\", end='\\n\\n')\n","print(f\"F1 Score without RAG: {F1_not_rag.mean():.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"v2M8WphC_0lw"},"source":["Языковым моделям были заданы следующие вопросы:\n","\n","1. Что такое информационная безопасность?\n","2. Что такое троянский конь?\n","3. Какая доля киберпреступлений в мире связана с воровством денег?\n","4. Когда были утверждены программы \"Цифровая экономика Российской Федерации\" на 2018-2024 гг.?\n","\n","Вопросы 1 и 2 имеют более общий характер, ответы на них модель может дать на основании данных, на которых она была обучена. Ответы на вопросы 3 и 4 можно найти в локальной базе знаний. В качестве эталонных ответов были взяты ответы, которые можно найти в локальной базе знаний.\n","\n","Ответы модели с использованием RAG и без использования RAG сравнивались с помошью BERTScore. Модель с использованием RAG имеет значение F1 = 0.7767, в то время как модель без использования RAG имеет значение F1 = 0.7124.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aYv75KhOaLf7"},"source":["### Выводы\n","\n","В процессе выполнения задания были выполнены следующие задачи:\n","\n","* На основании научных статей по тематике информационной безопасности была сформирована локальная база знаний\n","* Была разработана система, сочетающая генерацию текста с помощью модели Mixtral-8x7B-Instruct-v0.1 и использование метода RAG для поиска релевантной информации в локальной базе знаний\n","\n","Использование RAG повысило значение метрики F1, рассчитанной с помощью BERTScore, на ~7%.\n","\n","Для дальнейшего развития проекта можно предпринять следующие шаги:\n","\n","* Увеличение размера базы знаний и использование более разнообразных документов (например, законодательные акты в сфере информационной безопасности).\n","* Использование более продвинутых языковых моделей с бОльшим числом параметров, что затруднено при условии развертывания проекта в Google Colab.\n","* Для повышения точности ответов модели использовать более точную настройку промтов, few-shot, тюнинг гиперпараметров.\n","\n","После выполнения указанных пунктов чат-бот может быть внедрен в крупные компании в качестве ассистента для ответов на вопросы сотрудников по тематике информационной безопасности."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2_ncZWlfLeH"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"029f9bb071764be398ad2f464e4ee525":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_875b7782eeff43f0bed2d207500d7b06","placeholder":"​","style":"IPY_MODEL_57fd74bbca874284a0b76aa48cbf260e","value":"100%"}},"083c422dc2e24daa90b9e95d039b45b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd1172318dc4f1a98f073d8904fb58a","placeholder":"​","style":"IPY_MODEL_c6b6fa53fe9c4c0e929377f22255a8a0","value":" 1/1 [00:01&lt;00:00,  1.49s/it]"}},"320872f5753f4c20b9f2f33fb0c88174":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a2a1d855dad4038bddf32403bca197d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5084224c8be444e1a5360d26d1f60d95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"533f2c1749f94226bf0e787948963876":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55af2aa171f54f428e358497dc498b90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_320872f5753f4c20b9f2f33fb0c88174","placeholder":"​","style":"IPY_MODEL_9f1f637ba8de406a8a1eb033a4dabe01","value":" 1/1 [00:00&lt;00:00, 40.28it/s]"}},"577dfcf8e3584c48ab47e5cee8c364f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57fd74bbca874284a0b76aa48cbf260e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5df40df04aa54075b70c84a8f2e77aa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af673a51922144b0b6b4757debb71554","IPY_MODEL_60deac8cba034cae89f72a82b5ea53cd","IPY_MODEL_55af2aa171f54f428e358497dc498b90"],"layout":"IPY_MODEL_c290825bada64723977397109db2bd0e"}},"60deac8cba034cae89f72a82b5ea53cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e208f899180b4d1199db791c6e8b1f47","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf92911e49544c8580f9eb5b6c7322dd","value":1}},"635e1a64653c43f7befed1bbccaaff67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc7e00849c8748f1b957d11c758c669d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9b4876fba9743f09c65ddd1c6eb0bb8","value":1}},"6caae4af9b964b73b6145eb7568f5237":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cb6d9352ab643bebced37bbc7755a3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70836bb1f6b8424582b2410cb4a9f63f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b3373417ef8465e8c892d8cfc979c86","IPY_MODEL_d0a25884bd7e422881db7ce39d24e03a","IPY_MODEL_895d1c76affd4253b1c821daa1835343"],"layout":"IPY_MODEL_f99a79a2033941059af34dff55ed47ad"}},"7125359331174d94b3e0bca370c0ab3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b3373417ef8465e8c892d8cfc979c86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6caae4af9b964b73b6145eb7568f5237","placeholder":"​","style":"IPY_MODEL_899ab532917c465faee0d6d5e0d41b69","value":"100%"}},"7dd1172318dc4f1a98f073d8904fb58a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"851d7da245b14adab7678bf32e2a8ddb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"875b7782eeff43f0bed2d207500d7b06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"895d1c76affd4253b1c821daa1835343":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f62e48f8ce494b79860da7938f452c0c","placeholder":"​","style":"IPY_MODEL_533f2c1749f94226bf0e787948963876","value":" 1/1 [00:00&lt;00:00, 32.38it/s]"}},"899ab532917c465faee0d6d5e0d41b69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fc08880b8ad4ad9955a0d40033f8df5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e0b2e1c9354424a61d20c2f84bc8ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_577dfcf8e3584c48ab47e5cee8c364f2","placeholder":"​","style":"IPY_MODEL_3a2a1d855dad4038bddf32403bca197d","value":" 1/1 [00:01&lt;00:00,  1.11s/it]"}},"9dfb9e0c35a14540adb9b156435a3559":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_851d7da245b14adab7678bf32e2a8ddb","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5084224c8be444e1a5360d26d1f60d95","value":1}},"9f1f637ba8de406a8a1eb033a4dabe01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1ba567c1994448d810b6d2da6958099":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4a2a63556f743fa8db0b93af8b9876e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af673a51922144b0b6b4757debb71554":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb8da34da8f04bcc96bde60a795e27fe","placeholder":"​","style":"IPY_MODEL_a1ba567c1994448d810b6d2da6958099","value":"100%"}},"bf92911e49544c8580f9eb5b6c7322dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c290825bada64723977397109db2bd0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b6fa53fe9c4c0e929377f22255a8a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cabed5f1ebe546a98977a9124d4188f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cddb4e91388a4495928fb9b4dff517e1","placeholder":"​","style":"IPY_MODEL_7125359331174d94b3e0bca370c0ab3f","value":"100%"}},"cddb4e91388a4495928fb9b4dff517e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0a25884bd7e422881db7ce39d24e03a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fc08880b8ad4ad9955a0d40033f8df5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9f2b750cb7f4412b6880c2bd6c141ae","value":1}},"d5fd5899f0f2492c8181deaa5d2359d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_029f9bb071764be398ad2f464e4ee525","IPY_MODEL_635e1a64653c43f7befed1bbccaaff67","IPY_MODEL_083c422dc2e24daa90b9e95d039b45b9"],"layout":"IPY_MODEL_6cb6d9352ab643bebced37bbc7755a3c"}},"e208f899180b4d1199db791c6e8b1f47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b4876fba9743f09c65ddd1c6eb0bb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2511916b44b4c5a8d98985a138d14a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cabed5f1ebe546a98977a9124d4188f5","IPY_MODEL_9dfb9e0c35a14540adb9b156435a3559","IPY_MODEL_96e0b2e1c9354424a61d20c2f84bc8ec"],"layout":"IPY_MODEL_a4a2a63556f743fa8db0b93af8b9876e"}},"f62e48f8ce494b79860da7938f452c0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f99a79a2033941059af34dff55ed47ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f2b750cb7f4412b6880c2bd6c141ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb8da34da8f04bcc96bde60a795e27fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc7e00849c8748f1b957d11c758c669d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
